{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance of chat model\n",
    "chat_gpt = ChatOpenAI(model = 'gpt-4o-mini',temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['topic'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Explain {topic} in maximum 2 bullet points.'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# Creating a prompt template\n",
    "template = \"Explain {topic} in maximum 2 bullet points.\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Chain\n",
    "chain = (\n",
    "    prompt\n",
    "      |\n",
    "    chat_gpt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- **Definition**: Generative AI refers to algorithms and models that can create new content, such as text, images, music, or videos, by learning patterns from existing data. Examples include language models like GPT and image generators like DALL-E.\n",
       "\n",
       "- **Applications**: It is used in various fields, including creative arts, content generation, game design, and personalized marketing, enabling automation and innovation in producing high-quality, original outputs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Running the chain and getting the output\n",
    "response = chain.invoke({\"topic\" : \"Generative AI\"})\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Generative AI refers to algorithms and models that can create new content, such as text, images, music, or videos, by learning patterns from existing data. Examples include language models like GPT and image generators like DALL-E.\n",
      "\n",
      "- **Applications**: It is used in various fields, including creative arts, content generation, game design, and personalized marketing, enabling automation and innovation in producing high-quality, original outputs."
     ]
    }
   ],
   "source": [
    "# Streaming\n",
    "response = chain.stream({\"topic\" : \"Generative AI\"}, stream = True)\n",
    "for message in response:\n",
    "    print(message.content,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- **Definition**: Generative AI refers to a class of artificial intelligence models that can create new content, such as text, images, music, or videos, by learning patterns and structures from existing data.\n",
       "- **Applications**: It is used in various fields, including creative arts, content generation, drug discovery, and personalized marketing, enabling automation and innovation in content creation and problem-solving."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Hierarchical Feature Learning**: Deep learning utilizes neural networks with multiple layers to automatically learn and extract hierarchical features from raw data, enabling the model to capture complex patterns and representations.\n",
       "\n",
       "- **Large-Scale Data and Computation**: It thrives on large datasets and powerful computational resources, allowing for improved performance in tasks such as image recognition, natural language processing, and speech recognition."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# batch\n",
    "response = chain.batch([\"Generative AI\",\"Deep Learning\"])\n",
    "for message in response:\n",
    "    display(Markdown(message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- **Definition**: Generative AI refers to a class of artificial intelligence models that can create new content, such as text, images, music, or videos, by learning patterns and structures from existing data.\n",
       "- **Applications**: It is used in various fields, including creative arts, content generation, drug discovery, and personalized recommendations, enabling innovative solutions and enhancing productivity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# async invoking\n",
    "response = await chain.ainvoke({\"topic\" : \"Generative AI\"})\n",
    "display(Markdown(response.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
